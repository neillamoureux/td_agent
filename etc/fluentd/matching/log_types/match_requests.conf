<filter goliath.production.logs>
  @type record_transformer
  enable_ruby true
  renew_time_key ${record.dig("ht", "s")}
</filter>

<match goliath.production.logs>
  @type copy
  <store>
    @include ../include/combined_s3.conf
    path old/rawlogs/
    <buffer>
      @include ../include/combined_buffer.conf
      path /mnt/td-agent/rawlogs-s3buffer
    </buffer>
  </store>

  <store>
    @include ../include/split_s3.conf
    # Use hive format for partition names
    path new/match_requests/site=${$.p.sid}/dt=%Y-%m-%d-%H/
    s3_object_key_format "%{path}${$.p.sid}_%{time_slice}_%{index}.%{file_extension}"

    <buffer time, $.p.sid>
      @include ../include/split_buffer.conf
      path /mnt/td-agent/match_requests
    </buffer>
  </store>
</match>

